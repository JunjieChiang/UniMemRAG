{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee20f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/home/mobuser/jjj/UniMemRAG/examples/../unimemrag/vector_store/qdrant.py:40: UserWarning: Qdrant client version 1.14.3 is incompatible with server version 1.16.3. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  self.client = QdrantClient(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ.pop(\"http_proxy\", None)\n",
    "os.environ.pop(\"https_proxy\", None)\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from config import Config\n",
    "from unimemrag.retriever import ClipEmbedding\n",
    "from unimemrag.memory_forest.memory_forest import MemoryForestStore\n",
    "\n",
    "cfg = Config(collection=\"memtree\")                          \n",
    "embed_model = ClipEmbedding(model_name=\"../../ckpts/clip-vit-base-patch32\")\n",
    "memforest_store = MemoryForestStore(cfg, vector_size=embed_model.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from sklearn import tree\n",
    "os.environ.pop(\"http_proxy\", None)\n",
    "os.environ.pop(\"https_proxy\", None)\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import asdict\n",
    "from itertools import islice\n",
    "from tqdm.auto import tqdm\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "from unimemrag.memory_forest.memory_forest import build_tree, iter_wiki_dict\n",
    "from unimemrag.utils.image_cache import download_images_for_kb, load_image_cache, replace_payload_image_urls, save_image_cache\n",
    "\n",
    "llm = OpenAI(\n",
    "       api_key=\"sk-d6de5f2c6e4c458e9b53e9d96a5e75bb\",\n",
    "       base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "KB_PATH = Path(\"../../benchmark/infoseek/subset/wiki_text/wiki_5k_dict.json\")\n",
    "\n",
    "with KB_PATH.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "    KB = json.load(fh)\n",
    "\n",
    "IMAGE_CACHE_DIR = Path('../../benchmark/infoseek/subset/wiki_text/images_5k')\n",
    "IMAGE_CACHE_INDEX = IMAGE_CACHE_DIR / \"image_cache_index.json\"\n",
    "image_cache = load_image_cache(IMAGE_CACHE_INDEX)\n",
    "\n",
    "if not image_cache:\n",
    "    image_cache = download_images_for_kb(KB, IMAGE_CACHE_DIR, max_workers=64, resume=True)\n",
    "    save_image_cache(image_cache, IMAGE_CACHE_INDEX)\n",
    "else:\n",
    "    print(f\"Loaded {len(image_cache)} cached entries from {IMAGE_CACHE_INDEX}\")\n",
    "\n",
    "def localize_payload(payload):\n",
    "    return replace_payload_image_urls(dict(payload), image_cache)\n",
    "\n",
    "\n",
    "total = len(KB)\n",
    "iterator = islice(iter_wiki_dict(KB), total)\n",
    "iterator = tqdm(iterator, total=total, desc=\"Building Trees\")\n",
    "\n",
    "trees = []\n",
    "for wiki_url, payload in iterator:\n",
    "    payload = localize_payload(payload)\n",
    "    # tree = build_tree(wiki_url, payload)\n",
    "    tree = build_tree(\n",
    "       wiki_url,\n",
    "       payload,\n",
    "       llm=llm,\n",
    "       llm_model=\"qwen3-8b\",\n",
    "       max_summary_sections=None,\n",
    "       llm_workers=10,\n",
    "       llm_request_kwargs={\"max_tokens\": 512, \"temperature\": 0.7, \"extra_body\": {\"enable_thinking\": False}}\n",
    "       )      \n",
    "    trees.append(tree)\n",
    "\n",
    "TREES_OUT = Path(\"trees_5k.json\")\n",
    "with TREES_OUT.open(\"w\", encoding=\"utf-8\") as fh:\n",
    "    json.dump([asdict(t) for t in trees], fh, indent=2)\n",
    "print(f\"Saved {len(trees)} trees to {TREES_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5bab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load trees from file\n",
    "'''\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from unimemrag.memory_forest.memory_forest import MemoryTree, RootNode, EventNode, LeafNode\n",
    "\n",
    "TREES_OUT = Path(\"trees_5k.json\")\n",
    "\n",
    "with TREES_OUT.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "    data = json.load(fh)\n",
    "\n",
    "def tree_from_dict(d):\n",
    "    root = RootNode(**d[\"root\"])\n",
    "    events = [EventNode(**e) for e in d.get(\"events\", [])]\n",
    "    leaves = [LeafNode(**l) for l in d.get(\"leaves\", [])]\n",
    "    return MemoryTree(tree_id=d[\"tree_id\"], root=root, events=events, leaves=leaves)\n",
    "\n",
    "trees = [tree_from_dict(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4deebb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Trees (fused leaves):  56%|█████▌    | 30040/53538 [00:14<00:08, 2887.39it/s]/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (93083904 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (154443312 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Embedding Trees (fused leaves):  57%|█████▋    | 30694/53538 [00:29<00:07, 2887.39it/s]/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (134400000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (101523388 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (112390980 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (150000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Embedding Trees (fused leaves):  59%|█████▉    | 31718/53538 [02:14<05:32, 65.65it/s]  /home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (89972928 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (139105344 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Embedding Trees (fused leaves):  69%|██████▉   | 36838/53538 [04:17<06:51, 40.62it/s]/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (106254420 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Embedding Trees (fused leaves):  70%|██████▉   | 37350/53538 [04:20<05:14, 51.55it/s]/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (139095077 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "                                                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roots': 1166, 'events': 14553, 'leaves': 13809}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memforest_store.ingest_trees(\n",
    "#       trees,\n",
    "#       embed_model,\n",
    "#       batch_size=256,\n",
    "#       text_workers=16,\n",
    "#       image_workers=16,\n",
    "#       alpha=0.1,\n",
    "#       show_progress=True\n",
    "# )\n",
    "\n",
    "# 入库：多模态 leaf\n",
    "memforest_store.ingest_trees_new(\n",
    "    trees,\n",
    "    embed_model,\n",
    "    beta=0.4,\n",
    "    batch_size=512,\n",
    "    text_workers=16,\n",
    "    image_workers=16,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5d247c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobuser/miniconda3/envs/unimemrag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/home/mobuser/jjj/UniMemRAG/examples/../unimemrag/vector_store/qdrant.py:40: UserWarning: Qdrant client version 1.14.3 is incompatible with server version 1.16.3. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  self.client = QdrantClient(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading tree index from memforest store\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "os.environ.pop(\"http_proxy\", None)\n",
    "os.environ.pop(\"https_proxy\", None)\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1\"\n",
    "\n",
    "from config import Config\n",
    "from unimemrag.embedding.models.ClipEmbedding import ClipEmbedding\n",
    "from unimemrag.memory_forest import MemoryForestStore\n",
    "\n",
    "cfg = Config(collection=\"memtree\")\n",
    "embed_model = ClipEmbedding()\n",
    "memforest_store = MemoryForestStore(cfg, vector_size=embed_model.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8838fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = memforest_store.retrieve(\n",
    "#     embed_model,\n",
    "#     query_text=\"What is the closest parent taxonomy of this bird?\",\n",
    "#     query_image=\"../../benchmark/oven/05/oven_05037337.JPEG\",\n",
    "#     root_top_k=3,\n",
    "#     event_top_k=3,\n",
    "#     leaf_top_k=3,\n",
    "#     alpha=0.3,\n",
    "# )\n",
    "\n",
    "# 检索：collapsed retrieval\n",
    "results = memforest_store.collapsed_retrieve(\n",
    "    embed_model,\n",
    "    alpha=0.1,\n",
    "    query_text=\"where is this plant originally discovered?\",\n",
    "    query_image=\"../../benchmark/oven/05/oven_05031362\",\n",
    "    # query_image=\"../image.png\",\n",
    "    leaf_top_k=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[1].leaves\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in results:\n",
    "    print(\"=== Root:\", tree.root.payload.get(\"topic\"))\n",
    "    for event in tree.events:\n",
    "        sec_id = event.id\n",
    "        meta = event.payload.get(\"metadata\", {})\n",
    "        title = meta.get(\"section_title\") or event.payload.get(\"summary\")\n",
    "        section_chunks = [\n",
    "            leaf.payload[\"content\"]\n",
    "            for leaf in tree.leaves.get(sec_id, [])\n",
    "            if \"content\" in leaf.payload\n",
    "        ]\n",
    "        section_text = \"\\n\".join(section_chunks)\n",
    "        print(f\"\\nSection: {title}\")\n",
    "        print(\"Images:\", meta.get(\"section_images\", []))\n",
    "        print(\"Text:\", section_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a39579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memforest_store.client.delete_collection(memforest_store.cfg.collection)\n",
    "memforest_store.client.delete_collection(memforest_store.event_collection)\n",
    "memforest_store.client.delete_collection(memforest_store.leaf_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "memforest_store.client.count(memforest_store.roof_collection, exact=True)\n",
    "# memforest_store.client.count(memforest_store.leaf_collection, exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(res.root.payload[\"topic\"])\n",
    "    print(res.events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unimemrag.vlm.QwenVL import QwenVL\n",
    "vlm = QwenVL(\n",
    "    model_path=\"../../ckpts/Qwen2.5-VL-7B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0]\n",
    "\n",
    "def format_context(tree_result, top_sections=3, max_chars=1024):\n",
    "    root = tree_result.root\n",
    "    meta = root.payload.get(\"metadata\", {}) or {}\n",
    "    lines = [\n",
    "        f\"Topic: {root.payload.get('topic') or meta.get('source_url', 'n/a')}\",\n",
    "        f\"Tree ID: {tree_result.tree_id}\",\n",
    "        f\"Alignment score: {meta.get('alignment_best_score', 'n/a')}\",\n",
    "        \"\",\n",
    "    ]\n",
    "    for event in tree_result.events[:top_sections]:\n",
    "        emeta = event.payload.get(\"metadata\", {}) or {}\n",
    "        title = emeta.get(\"section_title\") or event.payload.get(\"summary\") or \"Unknown section\"\n",
    "        lines.append(f\"Section: {title}\")\n",
    "        section_preview = (emeta.get(\"section_preview\") or event.payload.get(\"summary\") or \"\").strip()\n",
    "        if section_preview:\n",
    "            lines.append(section_preview)\n",
    "        leaf_hits = tree_result.leaves.get(event.id, [])\n",
    "        for idx, leaf_hit in enumerate(leaf_hits[:2], start=1):\n",
    "            snippet = (leaf_hit.payload.get(\"content\") or \"\").strip()\n",
    "            if not snippet:\n",
    "                continue\n",
    "            lines.append(f\"Paragraph {idx}: {snippet}\")\n",
    "        lines.append(\"\")\n",
    "    context = \"\\n\".join(lines).strip()\n",
    "    if max_chars and max_chars > 0 and len(context) > max_chars:\n",
    "        truncated = context[:max_chars]\n",
    "        if \"\\n\" in truncated:\n",
    "            truncated = truncated.rsplit(\"\\n\", 1)[0]\n",
    "        context = truncated\n",
    "    return context\n",
    "\n",
    "context = format_context(result, top_sections=3)\n",
    "print(\"formated_context:\", context)\n",
    "question=\"Who built this object that has not cash dispensing features?\",\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"You are a helpful assistant. Please answer the question based on the context provided.\"}\n",
    "    ]},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\", \"image\": \"../atm-machine.jpg\"},\n",
    "        {\"type\": \"text\",  \"text\": f\"Here's the contexts:\\n{context}\\n\\nNow, answer the question:\\n{question}\"}\n",
    "    ]}\n",
    "]\n",
    "print(messages)\n",
    "\n",
    "answer = vlm.chat(messages, max_new_tokens=32768, temperature=0.7)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../benchmark/infoseek/wiki_text/wiki_100_dict_v4.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb752adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, v) in enumerate(data.items()):\n",
    "    print(f\"[{i}] {k} -> {list(v.keys())}\")\n",
    "    print(f\"[{i}] {k} -> topic: {v.get('title', [])} image_urls: {v.get('image_urls', [])}\")\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5933f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.pop(\"http_proxy\", None)\n",
    "os.environ.pop(\"https_proxy\", None)\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from unimemrag.embedding.models.ClipEmbedding import ClipEmbedding\n",
    "import numpy as np\n",
    "\n",
    "clip = ClipEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8182704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.pop(\"http_proxy\", None)\n",
    "os.environ.pop(\"https_proxy\", None)\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from unimemrag.retriever import ClipEmbedding\n",
    "\n",
    "embed_model = ClipEmbedding(model_name=\"../../ckpts/clip-vit-base-patch32\")\n",
    "\n",
    "topic = \"Reflecting telescope\"\n",
    "image_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/c/c1/ParasolMushroom.JPG\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/8/8c/Parasol-1.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/5/54/Glawlen_y_Bwgan_%28Macrolepiota_procera%29.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/a/a4/Macrolepiota-procera.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/d/d3/Macrolepiota_procera_fungus%2C_Woodfidley%2C_New_Forest_-_geograph.org.uk_-_261237.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/4/48/Macrolepiota_procera_2011_G1.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/c/cf/Parasol-Macrolepiota-procera.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/6/6a/Macrolepiota_procera_2013_G1.jpg\",\n",
    "    \"http://upload.wikimedia.org/wikipedia/commons/a/ab/Parasol_mushroom.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/d/da/Breaded_parasol_mushroom.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/1/1b/Edible_fungi_in_basket_2019_G2.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/f/f3/Unopened_parasol_mushroom.jpg\"\n",
    "    ]\n",
    "\n",
    "\n",
    "text_embed = embed_model.embed_texts([topic])[0]      # (dim,)\n",
    "image_embeds = embed_model.embed_images(image_urls)   # (N, dim)\n",
    "\n",
    "scores = image_embeds @ text_embed             # 余弦相似度\n",
    "for url, score in zip(image_urls, scores):\n",
    "    print(f\"{url} -> {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c4ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unimemrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
