"""
Minimal helpers for loading InfoSeek JSONL corpora.

The utilities below target the sampled KB files generated by
`examples/prepare_infoseek_kb.py`, such as
`benchmark/infoseek/wiki_text/infoseek_kb_100k_mm.jsonl`.
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

from datasets import Dataset


@dataclass(frozen=True)
class InfoSeekItem:
    """Lightweight representation of a single InfoSeek entry."""

    id: str
    title: str
    content: str
    summary: str
    image_url: Optional[str]
    local_image_path: Optional[str] = None

    def to_payload(self, *, prefer_summary: bool = True) -> Dict[str, Optional[str]]:
        """
        Convert the item into a dictionary ready for downstream processing.

        Args:
            prefer_summary: When True, `context` prioritises the summary text
                when available; otherwise the full article content is used.
        """

        context = (self.summary or "").strip() if prefer_summary else self.content
        if not context:
            context = self.content or self.summary or ""

        return {
            "id": self.id,
            "title": self.title,
            "context": context,
            "image_url": self.image_url,
            "summary": self.summary,
            "local_image_path": self.local_image_path,
        }


def load_infoseek_items(
    jsonl_path: str | Path,
    *,
    prefer_summary: bool = True,
) -> List[Dict[str, Optional[str]]]:
    """
    Load InfoSeek KB entries into a list of normalised dictionaries.

    Args:
        jsonl_path: Path to an InfoSeek JSONL file, e.g.
            `benchmark/infoseek/wiki_text/infoseek_kb_100k_mm.jsonl`.
        prefer_summary: When True, the emitted `context` favours the shorter
            `wikipedia_summary` over the full article content.

    Returns:
        List of dictionaries with keys: `id`, `title`, `context`,
        `image_url`, `summary`.
    """

    path = Path(jsonl_path).expanduser()
    if not path.is_file():
        raise FileNotFoundError(f"InfoSeek JSONL not found: {path}")

    items: List[Dict[str, Optional[str]]] = []

    with path.open("r", encoding="utf-8") as handle:
        for line_no, line in enumerate(handle, 1):
            stripped = line.strip()
            if not stripped:
                continue
            try:
                payload = json.loads(stripped)
            except json.JSONDecodeError as exc:
                raise ValueError(f"Invalid JSON at {path}:{line_no}") from exc

            wikidata_id = str(payload.get("wikidata_id") or "").strip()
            if not wikidata_id:
                raise ValueError(f"Missing `wikidata_id` at {path}:{line_no}")

            item = InfoSeekItem(
                id=wikidata_id,
                title=str(payload.get("wikipedia_title") or "").strip(),
                content=str(payload.get("wikipedia_content") or ""),
                summary=str(payload.get("wikipedia_summary") or ""),
                image_url=(str(payload["wikipedia_image_url"]).strip() or None)
                if payload.get("wikipedia_image_url")
                else None,
                local_image_path=(str(payload.get("local_image_path") or "").strip() or None),
            )
            items.append(item.to_payload(prefer_summary=prefer_summary))

    return items


def load_infoseek_dataset(
    jsonl_path: str | Path,
    *,
    prefer_summary: bool = True,
    filter_missing_images: bool = False,
) -> Dataset:
    """
    Load InfoSeek KB entries as a Hugging Face Dataset compatible with indexing helpers.

    Args:
        jsonl_path: Path to an InfoSeek JSONL knowledge base file.
        prefer_summary: When True, use the short summary for context when available.
        filter_missing_images: When True, drop rows that do not provide a local image path.

    Returns:
        Dataset where each row exposes an `id`, optional `image`, and `ctxs` list with
        normalised document dictionaries expected by `index_text_corpus` / `index_image_corpus`.
    """

    records = load_infoseek_items(jsonl_path, prefer_summary=prefer_summary)
    rows: List[Dict[str, Optional[str]]] = []

    for record in records:
        doc_id = record["id"]
        context = (record.get("context") or "").strip()
        if not context:
            continue

        local_image = record.get("local_image_path")
        if filter_missing_images and not local_image:
            continue

        ctx_payload: Dict[str, Optional[str]] = {
            "doc_id": doc_id,
            "title": record.get("title") or "",
            "text": context,
        }
        if record.get("image_url"):
            ctx_payload["image_url"] = record["image_url"]
        if local_image:
            ctx_payload["image"] = local_image

        row: Dict[str, Optional[str]] = {
            "id": doc_id,
            "ctxs": [ctx_payload],
        }
        if local_image:
            row["image"] = local_image
        rows.append(row)

    return Dataset.from_list(rows)
